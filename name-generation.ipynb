{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'facebook-names.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = file.read()\n",
    "    data=data.lower()\n",
    "    data=data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_level_dict(data):\n",
    "    char_to_index ={}\n",
    "    index_to_char ={}\n",
    "    total_char = \"\".join(data)\n",
    "    char_set= (set(\"\".join(data)))\n",
    "    special_character = '\\n'\n",
    "    char_set.add(special_character)\n",
    "    char_set = sorted(char_set)\n",
    "    for i, char in enumerate(char_set):\n",
    "        char_to_index[char] = i\n",
    "        index_to_char[i] = char\n",
    "    return char_to_index, index_to_char, char_set, total_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index, index_to_char,char_set,total_char = char_level_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 unique characters and 1889474 total characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "unique_char_size = len(char_set)\n",
    "total_char_size = len(total_char)\n",
    "print(f'There are {unique_char_size} unique characters and {total_char_size} total characters in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self,hidden_size,vocab_size,seq_length,learning_rate):\n",
    "        #hyper parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_length = seq_length\n",
    "        self.learning_rate = learning_rate\n",
    "        self.U = np.random.randn(hidden_size,vocab_size) #input to hidden\n",
    "        self.W = np.random.randn(hidden_size,hidden_size)\n",
    "        self.V = np.random.randn(vocab_size,hidden_size)\n",
    "        self.b = np.random.randn(hidden_size,1)\n",
    "        self.c = np.random.randn(vocab_size,1)\n",
    "\n",
    "    def softmax(self,x):\n",
    "        exps = np.exp(x-np.max(x))\n",
    "        return exps/np.sum(exps)\n",
    "\n",
    "    def forward(self,inputs, hprev):\n",
    "        xs, hs, os, ycap = {}, {}, {}, {}\n",
    "        hs[-1] = np.copy(hprev)\n",
    "        for t in range((len(inputs))):\n",
    "            xs[t] = np.zeros((vocab_size,1)) #creating an input vector for each character in the sequence\n",
    "            xs[t][inputs[t]] = 1 #one hot encoding\n",
    "            hs[t] = np.tanh(np.dot(self.U, xs[t]) + np.dot(self.W, hs[t-1]) + self.b)#hidden state and activation function tanh applied\n",
    "            os[t] = np.dot(self.V, hs[t]) + self.c #unnormalized log probabilities for next chars\n",
    "            ycap[t] = self.softmax(self.os[t])#output layer\n",
    "        return xs, hs,ycap\n",
    "    \n",
    "    def loss(self,ycap,targets):\n",
    "        return sum(-np.log(ycap[t][targets[t],0]) for t in range(len(targets)))\n",
    "    \n",
    "    def backward(self, xs, hs, ycap, targets):\n",
    "        dU, dW, dV = np.zeros_like(self.U), np.zeros_like(self.W), np.zeros_like(self.V)\n",
    "        db, dc = np.zeros_like(self.b), np.zeros_like(self.c)\n",
    "        dhnext = np.zeros_like(hs[0])\n",
    "        for t in reversed(range(len(targets))):\n",
    "            dy = np.copy(ycap[t])\n",
    "            dy[targets[t]] -= 1\n",
    "            dV += np.dot(dy, hs[t].T)\n",
    "            dc += dy\n",
    "            dh = np.dot(self.V.T, dy) + dhnext\n",
    "            dhraw = (1 - hs[t] * hs[t]) * dh\n",
    "            db += dhraw\n",
    "            dU += np.dot(dhraw, xs[t].T)\n",
    "            dW += np.dot(dhraw, hs[t-1].T)\n",
    "            dhnext = np.dot(self.W.T, dhraw)\n",
    "        for dparam in [dU, dW, dV, db, dc]:\n",
    "            np.clip(dparam, -5, 5, out=dparam)\n",
    "        return dU, dW, dV, db, dc, hs[len(targets)-1]\n",
    "    \n",
    "    def update_model(self, dU, dW, dV, db, dc):\n",
    "        for param, dparam in zip([self.U, self.W, self.V, self.b, self.c], [dU, dW, dV, db, dc]):\n",
    "            param += -self.learning_rate * dparam\n",
    "    \n",
    "    def sample(self,char_to_ix, seed):\n",
    "        x = np.zeros((self.vocab_size, 1))\n",
    "        a_prev = np.zeros((self.hidden_size,1))\n",
    "        indices = []\n",
    "        idx = -1\n",
    "        counter =0\n",
    "        new_line_character = char_to_ix['\\n']\n",
    "\n",
    "        while(idx!= new_line_character and counter !=50):\n",
    "            \n",
    "            a = np.tanh(np.dot(self.U,x) + np.dot(self.W,a_prev) + self.b)\n",
    "            z=np.dot(self.V,a) + self.c\n",
    "            y=self.softmax(z)\n",
    "\n",
    "            np.random.seed(counter+seed)\n",
    "\n",
    "            idx = np.random.choice(range(self.vocab_size), p=y.ravel())\n",
    "            indices.append(idx)\n",
    "            x = np.zeros((self.vocab_size, 1))\n",
    "            x[idx] = 1\n",
    "            a_prev = a\n",
    "            counter +=1\n",
    "            seed +=1\n",
    "        if(counter == 50):\n",
    "            indices.append(new_line_character)\n",
    "        return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(hidden_size=100, vocab_size=unique_char_size, seq_length=25, learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['l', 'b', 'e', 'e', '\\n']\n"
     ]
    }
   ],
   "source": [
    "indices = rnn.sample(char_to_index,1)\n",
    "print(len(indices))\n",
    "print([index_to_char[i] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(name) for name in data])\n",
    "X = np.zeros((len(data), max_len, unique_char_size), dtype=bool)\n",
    "y = np.zeros((len(data), unique_char_size), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(data):\n",
    "    for t, char in enumerate(name):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[name[-1]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 20, 27)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
